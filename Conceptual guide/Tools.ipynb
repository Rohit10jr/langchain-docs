{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938a6d84",
   "metadata": {},
   "source": [
    "**Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c774c36",
   "metadata": {},
   "source": [
    "*Key concepts*\n",
    "\n",
    "* Tools are a way to encapsulate a function and its schema in a way that can be passed to a chat model.\n",
    "* Create tools using the @tool decorator, which simplifies the process of tool creation, supporting the following:\n",
    "    1. Automatically infer the tool's name, description and expected arguments, while also supporting customization.\n",
    "    2. Defining tools that return artifacts (e.g. images, dataframes, etc.)\n",
    "    3. Hiding input arguments from the schema (and hence from the model) using injected tool arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bdaebd",
   "metadata": {},
   "source": [
    "*Create tools using the @tool decorator*\n",
    "\n",
    "The recommended way to create tools is using the @tool decorator. This decorator is designed to simplify the process of tool creation and should be used in most cases. After defining a function, you can decorate it with @tool to create a tool that implements the Tool Interface.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1a4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "   \"\"\"Multiply two numbers.\"\"\"\n",
    "   return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5ad0f",
   "metadata": {},
   "source": [
    "LangChain has a few other ways to create tools; e.g., by sub-classing the BaseTool class or by using StructuredTool. These methods are shown in the how to create custom tools guide, but we generally recommend using the @tool decorator for most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489d3da",
   "metadata": {},
   "source": [
    "*Use the tool directly*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5937e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = multiply.invoke({\"a\": 2, \"b\": 3})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afa421",
   "metadata": {},
   "source": [
    "Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae236ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc7e49",
   "metadata": {},
   "source": [
    "*Configuring the schema*\n",
    "\n",
    "The @tool decorator offers additional options to configure the schema of the tool (e.g., modify name, description or parse the function's doc-string to infer the schema).\n",
    "\n",
    "Please see the API reference for @tool for more details and review the how to create custom tools guide for examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccc0ad",
   "metadata": {},
   "source": [
    "*Tool artifacts*\n",
    "\n",
    "There are artifacts of a tool's execution that we want to make accessible to downstream components in our chain or agent, but that we don't want to expose to the model itself. For example if a tool returns a custom object, a dataframe or an image, we may want to pass some metadata about this output to the model without passing the actual output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def some_tool(...) -> Tuple[str, Any]:\n",
    "    \"\"\"Tool that does something.\"\"\"\n",
    "    ...\n",
    "    return 'Message for chat model', some_artifact "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc417ce",
   "metadata": {},
   "source": [
    "*Special type annotations*\n",
    "\n",
    "The following type annotations will end up removing the argument from the tool's schema. This can be useful for arguments that should not be exposed to the model and that the model should not be able to control.\n",
    "\n",
    "1. InjectedToolArg: Value should be injected manually at runtime using .invoke or .ainvoke.\n",
    "2. RunnableConfig: Pass in the RunnableConfig object to the tool.\n",
    "3. InjectedState: Pass in the overall state of the LangGraph graph to the tool.\n",
    "4. InjectedStore: Pass in the LangGraph store object to the tool.\n",
    "\n",
    "You can also use the Annotated type with a string literal to provide a description for the corresponding argument that WILL be exposed in the tool's schema.\n",
    "\n",
    "    Annotated[..., \"string literal\"] -- Adds a description to the argument that will be exposed in the tool's schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600f3f1",
   "metadata": {},
   "source": [
    "*InjectedToolArg*\n",
    "\n",
    "There are cases where certain arguments need to be passed to a tool at runtime but should not be generated by the model itself. For this, we use the InjectedToolArg annotation, which allows certain parameters to be hidden from the tool's schema.\n",
    "\n",
    "For example, if a tool requires a use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc204fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, InjectedToolArg\n",
    "\n",
    "@tool\n",
    "def user_specific_tool(input_data: str, user_id: InjectedToolArg) -> str:\n",
    "    \"\"\"Tool that processes input data.\"\"\"\n",
    "    return f\"User {user_id} processed {input_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd656793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1180fed3",
   "metadata": {},
   "source": [
    "*RunnableConfig*\n",
    "\n",
    "You can use the RunnableConfig object to pass custom run time values to tools.\n",
    "\n",
    "The config will not be part of the tool's schema and will be injected at runtime with appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "@tool\n",
    "async def some_func(..., config: RunnableConfig) -> ...:\n",
    "    \"\"\"Tool that does something.\"\"\"\n",
    "    # do something with config\n",
    "    ...\n",
    "\n",
    "await some_func.ainvoke(..., config={\"configurable\": {\"value\": \"some_value\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c43e2f",
   "metadata": {},
   "source": [
    "*Best practices*\n",
    "\n",
    "When designing tools to be used by models, keep the following in mind:\n",
    "\n",
    "* Tools that are well-named, correctly-documented and properly type-hinted are easier for models to use.\n",
    "* Design simple and narrowly scoped tools, as they are easier for models to use correctly.\n",
    "* Use chat models that support tool-calling APIs to take advantage of tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853dabc2",
   "metadata": {},
   "source": [
    "*ToolKits*\n",
    "\n",
    "LangChain has a concept of toolkits. This a very thin abstraction that groups tools together that are designed to be used together for specific tasks.\n",
    "\n",
    "All Toolkits expose a get_tools method which returns a list of tools. You can therefore do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a toolkit\n",
    "toolkit = ExampleTookit(...)\n",
    "\n",
    "# Get list of tools\n",
    "tools = toolkit.get_tools()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
