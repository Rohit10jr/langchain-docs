{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf25ce5",
   "metadata": {},
   "source": [
    "**Classify Text into Labels**\n",
    "\n",
    "Tagging means labeling a document with classes such as:\n",
    "\n",
    "Sentiment, Language, Style (formal, informal etc.), Covered topics, Political tendency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d743c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-1.5-pro-latest\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f9493",
   "metadata": {},
   "source": [
    "Let's specify a Pydantic model with a few properties and their expected type in our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6a8b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n",
    "\n",
    "# LLM\n",
    "llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-2.0-flash\").with_structured_output(\n",
    "    Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aa5b056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='Positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85dabd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'Negative', 'aggressiveness': 10, 'language': 'Spanish'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312b780",
   "metadata": {},
   "source": [
    "*Finer control*\n",
    "\n",
    "Careful schema definition gives us more control over the model's output.\n",
    "\n",
    "Specifically, we can define:\n",
    "\n",
    "Possible values for each property,\n",
    "Description to make sure that the model understands the property,\n",
    "Required properties to be returned,\n",
    "\n",
    "Let's redeclare our Pydantic model to control for each of the previously mentioned aspects using enums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98d4333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Classifications(BaseModel):\n",
    "    sentimentsss: str = Field(..., description=\"Describes the sentiment of the statement (e.g., happy, neutral, sad).\")\n",
    "    aggressivenesss: int = Field(\n",
    "        ...,\n",
    "        description=\"Describes how aggressive the statement is. The higher the number, the more aggressive.\",\n",
    "    )\n",
    "    languagesss: str = Field(\n",
    "        ..., description=\"Specifies the language of the statement (e.g., Spanish, English, French, etc.).\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# class Classifications(BaseModel):\n",
    "#     sentiment: str = Field(description=\"The sentiment of the text\", enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "#     aggressiveness: int = Field(\n",
    "#         description=\"describes how aggressive the statement is, the higher the number the more aggressive\", enum=[1, 2, 3, 4, 5])\n",
    "#     language: str = Field(description=\"The language the text is written in\", enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b3811",
   "metadata": {},
   "source": [
    "***enum is not working with gemini***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5198e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Extract the desired information from the following passage.\n",
    "    Only extract the properties mentioned in the 'Classification' function.\n",
    "    Passage:\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(temperature=0, model=\"gemini-2.0-flash\").with_structured_output(Classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2400ff03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'properties': {'sentimentsss': {'description': 'Describes the sentiment of the statement (e.g., happy, neutral, sad).', 'title': 'Sentimentsss', 'type': 'string'}, 'aggressivenesss': {'description': 'Describes how aggressive the statement is. The higher the number, the more aggressive.', 'title': 'Aggressivenesss', 'type': 'integer'}, 'languagesss': {'description': 'Specifies the language of the statement (e.g., Spanish, English, French, etc.).', 'title': 'Languagesss', 'type': 'string'}}, 'required': ['sentimentsss', 'aggressivenesss', 'languagesss'], 'title': 'Classifications', 'type': 'object'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\New\\AppData\\Local\\Temp\\ipykernel_19508\\632727839.py:3: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(Classifications.schema())\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(Classifications, type)\n",
    "print(isinstance(Classifications, type))\n",
    "print(Classifications.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2553d",
   "metadata": {},
   "source": [
    "Now the answers will be restricted in a way we expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45889faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifications(sentimentsss='happy', aggressivenesss=0, languagesss='Spanish')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c73f1891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifications(sentimentsss='angry', aggressivenesss=9, languagesss='Spanish')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "963099e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifications(sentimentsss='neutral', aggressivenesss=0, languagesss='English')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "llm.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
